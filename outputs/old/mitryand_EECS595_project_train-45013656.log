Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.11.crossattention.masked_bias', 'h.10.crossattention.c_attn.weight', 'h.8.crossattention.masked_bias', 'h.4.crossattention.masked_bias', 'h.11.crossattention.c_attn.weight', 'h.2.crossattention.c_attn.weight', 'h.11.ln_cross_attn.weight', 'h.11.crossattention.q_attn.weight', 'h.1.crossattention.masked_bias', 'h.10.ln_cross_attn.weight', 'h.9.crossattention.masked_bias', 'h.2.ln_cross_attn.weight', 'h.8.ln_cross_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.1.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.weight', 'h.1.crossattention.q_attn.weight', 'h.4.crossattention.bias', 'h.0.ln_cross_attn.weight', 'h.9.crossattention.c_attn.weight', 'h.3.crossattention.masked_bias', 'h.10.crossattention.q_attn.weight', 'h.6.ln_cross_attn.weight', 'h.2.crossattention.q_attn.weight', 'h.7.crossattention.c_attn.weight', 'h.5.crossattention.q_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.bias', 'h.3.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.4.crossattention.q_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.0.crossattention.q_attn.weight', 'h.4.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.11.crossattention.bias', 'h.9.ln_cross_attn.weight', 'h.10.crossattention.masked_bias', 'h.1.crossattention.c_proj.weight', 'h.5.crossattention.c_attn.weight', 'h.7.crossattention.masked_bias', 'h.2.crossattention.masked_bias', 'h.7.crossattention.c_proj.weight', 'h.6.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.5.ln_cross_attn.weight', 'h.7.ln_cross_attn.weight', 'h.9.crossattention.q_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.3.crossattention.bias', 'h.7.crossattention.bias', 'h.8.crossattention.bias', 'h.0.crossattention.masked_bias', 'h.7.crossattention.q_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.2.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.5.crossattention.bias', 'h.0.crossattention.bias', 'h.8.crossattention.c_attn.weight', 'h.1.ln_cross_attn.weight', 'h.0.crossattention.c_proj.weight', 'h.5.crossattention.masked_bias', 'h.9.crossattention.c_proj.weight', 'h.8.crossattention.c_proj.weight', 'h.6.crossattention.masked_bias', 'h.3.crossattention.q_attn.weight', 'h.0.crossattention.c_attn.weight', 'h.8.crossattention.q_attn.weight', 'h.10.crossattention.c_proj.weight', 'h.3.crossattention.c_proj.bias', 'h.3.ln_cross_attn.weight', 'h.11.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.weight', 'h.9.crossattention.bias', 'h.0.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.10.crossattention.bias', 'h.6.crossattention.bias', 'h.2.crossattention.bias', 'h.1.crossattention.bias', 'h.2.crossattention.c_proj.weight', 'h.4.ln_cross_attn.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
loaded 232 training samples
loaded 53 validation samples
loaded 6 test samples
created model
Begin training!
  0%|          | 0/232 [00:00<?, ?it/s]/home/mitryand/.local/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.
  warnings.warn(DEPRECATION_WARNING, FutureWarning)
  0%|          | 1/232 [00:01<05:28,  1.42s/it]  1%|          | 2/232 [00:02<03:53,  1.02s/it]  1%|▏         | 3/232 [00:02<03:23,  1.13it/s]  2%|▏         | 4/232 [00:03<03:08,  1.21it/s]  2%|▏         | 5/232 [00:04<03:00,  1.26it/s]  3%|▎         | 6/232 [00:05<02:55,  1.29it/s]  3%|▎         | 7/232 [00:05<02:51,  1.31it/s]  3%|▎         | 8/232 [00:06<02:48,  1.33it/s]  4%|▍         | 9/232 [00:07<02:46,  1.34it/s]  4%|▍         | 10/232 [00:08<02:45,  1.34it/s]  5%|▍         | 11/232 [00:08<02:44,  1.35it/s]  5%|▌         | 12/232 [00:09<02:43,  1.35it/s]  6%|▌         | 13/232 [00:10<02:42,  1.35it/s]  6%|▌         | 14/232 [00:10<02:41,  1.35it/s]  6%|▋         | 15/232 [00:11<02:40,  1.36it/s]  7%|▋         | 16/232 [00:12<02:39,  1.36it/s]  7%|▋         | 17/232 [00:13<02:38,  1.36it/s]  8%|▊         | 18/232 [00:13<02:37,  1.36it/s]  8%|▊         | 19/232 [00:14<02:36,  1.36it/s]  9%|▊         | 20/232 [00:15<02:35,  1.36it/s]  9%|▉         | 21/232 [00:16<02:35,  1.36it/s]  9%|▉         | 22/232 [00:16<02:34,  1.36it/s] 10%|▉         | 23/232 [00:17<02:33,  1.36it/s] 10%|█         | 24/232 [00:18<02:32,  1.36it/s] 11%|█         | 25/232 [00:19<02:32,  1.36it/s] 11%|█         | 26/232 [00:19<02:31,  1.36it/s] 12%|█▏        | 27/232 [00:20<02:30,  1.36it/s] 12%|█▏        | 28/232 [00:21<02:30,  1.36it/s] 12%|█▎        | 29/232 [00:22<02:29,  1.36it/s] 13%|█▎        | 30/232 [00:22<02:28,  1.36it/s] 13%|█▎        | 31/232 [00:23<02:28,  1.36it/s] 14%|█▍        | 32/232 [00:24<02:27,  1.36it/s] 14%|█▍        | 33/232 [00:24<02:26,  1.36it/s] 15%|█▍        | 34/232 [00:25<02:26,  1.36it/s] 15%|█▌        | 35/232 [00:26<02:25,  1.35it/s] 16%|█▌        | 36/232 [00:27<02:24,  1.35it/s] 16%|█▌        | 37/232 [00:27<02:24,  1.35it/s] 16%|█▋        | 38/232 [00:28<02:23,  1.35it/s] 17%|█▋        | 39/232 [00:29<02:22,  1.35it/s] 17%|█▋        | 40/232 [00:30<02:22,  1.35it/s] 18%|█▊        | 41/232 [00:30<02:21,  1.35it/s] 18%|█▊        | 42/232 [00:31<02:20,  1.35it/s] 19%|█▊        | 43/232 [00:32<02:19,  1.35it/s] 19%|█▉        | 44/232 [00:33<02:19,  1.35it/s] 19%|█▉        | 45/232 [00:33<02:18,  1.35it/s] 20%|█▉        | 46/232 [00:34<02:17,  1.35it/s] 20%|██        | 47/232 [00:35<02:16,  1.35it/s] 21%|██        | 48/232 [00:36<02:16,  1.35it/s] 21%|██        | 49/232 [00:36<02:15,  1.35it/s] 22%|██▏       | 50/232 [00:37<02:14,  1.35it/s] 22%|██▏       | 51/232 [00:38<02:13,  1.35it/s] 22%|██▏       | 52/232 [00:39<02:13,  1.35it/s] 23%|██▎       | 53/232 [00:39<02:12,  1.35it/s] 23%|██▎       | 54/232 [00:40<02:11,  1.35it/s] 24%|██▎       | 55/232 [00:41<02:10,  1.35it/s] 24%|██▍       | 56/232 [00:41<02:10,  1.35it/s] 25%|██▍       | 57/232 [00:42<02:09,  1.35it/s] 25%|██▌       | 58/232 [00:43<02:08,  1.35it/s] 25%|██▌       | 59/232 [00:44<02:08,  1.35it/s] 26%|██▌       | 60/232 [00:44<02:07,  1.35it/s] 26%|██▋       | 61/232 [00:45<02:06,  1.35it/s] 27%|██▋       | 62/232 [00:46<02:05,  1.35it/s] 27%|██▋       | 63/232 [00:47<02:05,  1.35it/s] 28%|██▊       | 64/232 [00:47<02:04,  1.35it/s] 28%|██▊       | 65/232 [00:48<02:03,  1.35it/s] 28%|██▊       | 66/232 [00:49<02:02,  1.35it/s] 29%|██▉       | 67/232 [00:50<02:02,  1.35it/s] 29%|██▉       | 68/232 [00:50<02:01,  1.35it/s] 30%|██▉       | 69/232 [00:51<02:00,  1.35it/s] 30%|███       | 70/232 [00:52<02:00,  1.35it/s] 31%|███       | 71/232 [00:53<01:59,  1.35it/s] 31%|███       | 72/232 [00:53<01:58,  1.35it/s] 31%|███▏      | 73/232 [00:54<01:57,  1.35it/s] 32%|███▏      | 74/232 [00:55<01:57,  1.35it/s] 32%|███▏      | 75/232 [00:56<01:56,  1.35it/s] 33%|███▎      | 76/232 [00:56<01:55,  1.35it/s] 33%|███▎      | 77/232 [00:57<01:55,  1.35it/s] 34%|███▎      | 78/232 [00:58<01:54,  1.35it/s] 34%|███▍      | 79/232 [00:59<01:53,  1.35it/s] 34%|███▍      | 80/232 [00:59<01:52,  1.35it/s] 35%|███▍      | 81/232 [01:00<01:52,  1.35it/s] 35%|███▌      | 82/232 [01:01<01:51,  1.35it/s] 36%|███▌      | 83/232 [01:02<01:50,  1.35it/s] 36%|███▌      | 84/232 [01:02<01:49,  1.35it/s] 37%|███▋      | 85/232 [01:03<01:49,  1.35it/s] 37%|███▋      | 86/232 [01:04<01:48,  1.35it/s] 38%|███▊      | 87/232 [01:04<01:47,  1.34it/s] 38%|███▊      | 88/232 [01:05<01:47,  1.35it/s] 38%|███▊      | 89/232 [01:06<01:46,  1.34it/s] 39%|███▉      | 90/232 [01:07<01:45,  1.34it/s] 39%|███▉      | 91/232 [01:07<01:44,  1.34it/s] 40%|███▉      | 92/232 [01:08<01:44,  1.34it/s] 40%|████      | 93/232 [01:09<01:43,  1.34it/s] 41%|████      | 94/232 [01:10<01:42,  1.34it/s] 41%|████      | 95/232 [01:10<01:41,  1.34it/s] 41%|████▏     | 96/232 [01:11<01:41,  1.34it/s] 42%|████▏     | 97/232 [01:12<01:40,  1.34it/s] 42%|████▏     | 98/232 [01:13<01:39,  1.34it/s] 43%|████▎     | 99/232 [01:13<01:38,  1.34it/s] 43%|████▎     | 100/232 [01:14<01:38,  1.34it/s] 44%|████▎     | 101/232 [01:15<01:37,  1.34it/s] 44%|████▍     | 102/232 [01:16<01:36,  1.34it/s] 44%|████▍     | 103/232 [01:16<01:36,  1.34it/s] 45%|████▍     | 104/232 [01:17<01:35,  1.34it/s] 45%|████▌     | 105/232 [01:18<01:34,  1.34it/s] 46%|████▌     | 106/232 [01:19<01:33,  1.34it/s] 46%|████▌     | 107/232 [01:19<01:33,  1.34it/s] 47%|████▋     | 108/232 [01:20<01:32,  1.34it/s] 47%|████▋     | 109/232 [01:21<01:31,  1.34it/s] 47%|████▋     | 110/232 [01:22<01:30,  1.34it/s] 48%|████▊     | 111/232 [01:22<01:30,  1.34it/s] 48%|████▊     | 112/232 [01:23<01:29,  1.34it/s] 49%|████▊     | 113/232 [01:24<01:28,  1.34it/s] 49%|████▉     | 114/232 [01:25<01:27,  1.34it/s] 50%|████▉     | 115/232 [01:25<01:27,  1.34it/s] 50%|█████     | 116/232 [01:26<01:26,  1.34it/s] 50%|█████     | 117/232 [01:27<01:25,  1.34it/s] 51%|█████     | 118/232 [01:28<01:24,  1.34it/s] 51%|█████▏    | 119/232 [01:28<01:24,  1.34it/s] 52%|█████▏    | 120/232 [01:29<01:23,  1.34it/s] 52%|█████▏    | 121/232 [01:30<01:22,  1.34it/s] 53%|█████▎    | 122/232 [01:31<01:22,  1.34it/s] 53%|█████▎    | 123/232 [01:31<01:21,  1.34it/s] 53%|█████▎    | 124/232 [01:32<01:20,  1.34it/s] 54%|█████▍    | 125/232 [01:33<01:19,  1.34it/s] 54%|█████▍    | 126/232 [01:34<01:19,  1.34it/s] 55%|█████▍    | 127/232 [01:34<01:18,  1.34it/s] 55%|█████▌    | 128/232 [01:35<01:17,  1.34it/s] 56%|█████▌    | 129/232 [01:36<01:16,  1.34it/s] 56%|█████▌    | 130/232 [01:37<01:16,  1.34it/s] 56%|█████▋    | 131/232 [01:37<01:15,  1.34it/s] 57%|█████▋    | 132/232 [01:38<01:14,  1.34it/s] 57%|█████▋    | 133/232 [01:39<01:13,  1.34it/s] 58%|█████▊    | 134/232 [01:39<01:13,  1.34it/s] 58%|█████▊    | 135/232 [01:40<01:12,  1.34it/s] 59%|█████▊    | 136/232 [01:41<01:11,  1.34it/s] 59%|█████▉    | 137/232 [01:42<01:10,  1.34it/s] 59%|█████▉    | 138/232 [01:42<01:10,  1.34it/s] 60%|█████▉    | 139/232 [01:43<01:09,  1.34it/s] 60%|██████    | 140/232 [01:44<01:08,  1.34it/s] 61%|██████    | 141/232 [01:45<01:07,  1.34it/s] 61%|██████    | 142/232 [01:45<01:07,  1.34it/s] 62%|██████▏   | 143/232 [01:46<01:06,  1.34it/s] 62%|██████▏   | 144/232 [01:47<01:05,  1.34it/s] 62%|██████▎   | 145/232 [01:48<01:04,  1.34it/s] 63%|██████▎   | 146/232 [01:48<01:04,  1.34it/s] 63%|██████▎   | 147/232 [01:49<01:03,  1.34it/s] 64%|██████▍   | 148/232 [01:50<01:02,  1.34it/s] 64%|██████▍   | 149/232 [01:51<01:01,  1.34it/s] 65%|██████▍   | 150/232 [01:51<01:01,  1.34it/s] 65%|██████▌   | 151/232 [01:52<01:00,  1.34it/s] 66%|██████▌   | 152/232 [01:53<00:59,  1.34it/s] 66%|██████▌   | 153/232 [01:54<00:58,  1.34it/s] 66%|██████▋   | 154/232 [01:54<00:58,  1.34it/s] 67%|██████▋   | 155/232 [01:55<00:57,  1.34it/s] 67%|██████▋   | 156/232 [01:56<00:56,  1.34it/s] 68%|██████▊   | 157/232 [01:57<00:56,  1.34it/s] 68%|██████▊   | 158/232 [01:57<00:55,  1.34it/s] 69%|██████▊   | 159/232 [01:58<00:54,  1.34it/s] 69%|██████▉   | 160/232 [01:59<00:53,  1.34it/s] 69%|██████▉   | 161/232 [02:00<00:53,  1.34it/s] 70%|██████▉   | 162/232 [02:00<00:52,  1.34it/s] 70%|███████   | 163/232 [02:01<00:51,  1.34it/s] 71%|███████   | 164/232 [02:02<00:50,  1.34it/s] 71%|███████   | 165/232 [02:03<00:50,  1.34it/s] 72%|███████▏  | 166/232 [02:03<00:49,  1.34it/s] 72%|███████▏  | 167/232 [02:04<00:48,  1.34it/s] 72%|███████▏  | 168/232 [02:05<00:47,  1.34it/s] 73%|███████▎  | 169/232 [02:06<00:47,  1.34it/s] 73%|███████▎  | 170/232 [02:06<00:46,  1.34it/s] 74%|███████▎  | 171/232 [02:07<00:45,  1.34it/s] 74%|███████▍  | 172/232 [02:08<00:44,  1.34it/s] 75%|███████▍  | 173/232 [02:09<00:44,  1.34it/s] 75%|███████▌  | 174/232 [02:09<00:43,  1.34it/s] 75%|███████▌  | 175/232 [02:10<00:42,  1.34it/s] 76%|███████▌  | 176/232 [02:11<00:41,  1.34it/s] 76%|███████▋  | 177/232 [02:12<00:41,  1.34it/s] 77%|███████▋  | 178/232 [02:12<00:40,  1.34it/s] 77%|███████▋  | 179/232 [02:13<00:39,  1.34it/s] 78%|███████▊  | 180/232 [02:14<00:38,  1.34it/s] 78%|███████▊  | 181/232 [02:15<00:38,  1.34it/s] 78%|███████▊  | 182/232 [02:15<00:37,  1.34it/s] 79%|███████▉  | 183/232 [02:16<00:36,  1.34it/s] 79%|███████▉  | 184/232 [02:17<00:35,  1.34it/s] 80%|███████▉  | 185/232 [02:18<00:35,  1.34it/s] 80%|████████  | 186/232 [02:18<00:34,  1.34it/s] 81%|████████  | 187/232 [02:19<00:33,  1.34it/s] 81%|████████  | 188/232 [02:20<00:32,  1.34it/s] 81%|████████▏ | 189/232 [02:21<00:32,  1.34it/s] 82%|████████▏ | 190/232 [02:21<00:31,  1.34it/s] 82%|████████▏ | 191/232 [02:22<00:30,  1.34it/s] 83%|████████▎ | 192/232 [02:23<00:29,  1.34it/s] 83%|████████▎ | 193/232 [02:24<00:29,  1.34it/s] 84%|████████▎ | 194/232 [02:24<00:28,  1.34it/s] 84%|████████▍ | 195/232 [02:25<00:27,  1.34it/s] 84%|████████▍ | 196/232 [02:26<00:26,  1.34it/s] 85%|████████▍ | 197/232 [02:27<00:26,  1.34it/s] 85%|████████▌ | 198/232 [02:27<00:25,  1.34it/s] 86%|████████▌ | 199/232 [02:28<00:24,  1.34it/s] 86%|████████▌ | 200/232 [02:29<00:23,  1.34it/s] 87%|████████▋ | 201/232 [02:30<00:23,  1.34it/s] 87%|████████▋ | 202/232 [02:30<00:22,  1.34it/s] 88%|████████▊ | 203/232 [02:31<00:21,  1.34it/s] 88%|████████▊ | 204/232 [02:32<00:20,  1.34it/s] 88%|████████▊ | 205/232 [02:33<00:20,  1.34it/s] 89%|████████▉ | 206/232 [02:33<00:19,  1.34it/s] 89%|████████▉ | 207/232 [02:34<00:18,  1.34it/s] 90%|████████▉ | 208/232 [02:35<00:17,  1.34it/s] 90%|█████████ | 209/232 [02:36<00:17,  1.34it/s] 91%|█████████ | 210/232 [02:36<00:16,  1.34it/s] 91%|█████████ | 211/232 [02:37<00:15,  1.34it/s] 91%|█████████▏| 212/232 [02:38<00:14,  1.34it/s] 92%|█████████▏| 213/232 [02:39<00:14,  1.34it/s] 92%|█████████▏| 214/232 [02:39<00:13,  1.34it/s] 93%|█████████▎| 215/232 [02:40<00:12,  1.34it/s] 93%|█████████▎| 216/232 [02:41<00:11,  1.34it/s] 94%|█████████▎| 217/232 [02:42<00:11,  1.34it/s] 94%|█████████▍| 218/232 [02:42<00:10,  1.34it/s] 94%|█████████▍| 219/232 [02:43<00:09,  1.34it/s] 95%|█████████▍| 220/232 [02:44<00:08,  1.34it/s] 95%|█████████▌| 221/232 [02:45<00:08,  1.34it/s] 96%|█████████▌| 222/232 [02:45<00:07,  1.34it/s] 96%|█████████▌| 223/232 [02:46<00:06,  1.34it/s] 97%|█████████▋| 224/232 [02:47<00:05,  1.34it/s] 97%|█████████▋| 225/232 [02:48<00:05,  1.34it/s] 97%|█████████▋| 226/232 [02:48<00:04,  1.34it/s] 98%|█████████▊| 227/232 [02:49<00:03,  1.34it/s] 98%|█████████▊| 228/232 [02:50<00:02,  1.34it/s] 99%|█████████▊| 229/232 [02:51<00:02,  1.34it/s] 99%|█████████▉| 230/232 [02:51<00:01,  1.34it/s]100%|█████████▉| 231/232 [02:52<00:00,  1.34it/s]100%|██████████| 232/232 [02:52<00:00,  1.55it/s]loss: 0.9139676094055176
Traceback (most recent call last):
  File "/home/mitryand/EECS-595-Final-Project-Style-Transfer/train_model.py", line 175, in <module>
    main(params)
  File "/home/mitryand/EECS-595-Final-Project-Style-Transfer/train_model.py", line 156, in main
    model = train(model, train_dataloader, eval_dataloader, params)
  File "/home/mitryand/EECS-595-Final-Project-Style-Transfer/train_model.py", line 130, in train
    outputs = model(input_ids=batch[0])
  File "/home/mitryand/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/mitryand/.local/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py", line 617, in forward
    decoder_outputs = self.decoder(
  File "/home/mitryand/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/mitryand/.local/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 1046, in forward
    transformer_outputs = self.transformer(
  File "/home/mitryand/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/mitryand/.local/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 776, in forward
    raise ValueError("You have to specify either input_ids or inputs_embeds")
ValueError: You have to specify either input_ids or inputs_embeds
100%|██████████| 232/232 [02:53<00:00,  1.34it/s]
