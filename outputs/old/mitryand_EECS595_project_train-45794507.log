If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`
loaded 1220 training samples
loaded 273 validation samples
loaded 33 test samples
Begin testing style transfer!
Traceback (most recent call last):
  File "/home/mitryand/EECS-595-Final-Project-Style-Transfer/train_model.py", line 416, in <module>
    main(params)
  File "/home/mitryand/EECS-595-Final-Project-Style-Transfer/train_model.py", line 397, in main
    evaluate_transfer(model,classifier, train_dataloader, eval_dataloader, params, input_tokenizer, output_tokenizer)
  File "/home/mitryand/EECS-595-Final-Project-Style-Transfer/train_model.py", line 185, in evaluate_transfer
    z_alt = fgim_attack(model, classifier, ((cls_pred + 1)%2), z)
  File "/home/mitryand/EECS-595-Final-Project-Style-Transfer/train_model.py", line 59, in fgim_attack
    sentence_og.requires_grad=False
RuntimeError: you can only change requires_grad flags of leaf variables. If you want to use a computed variable in a subgraph that doesn't require differentiation use var_no_grad = var.detach().
